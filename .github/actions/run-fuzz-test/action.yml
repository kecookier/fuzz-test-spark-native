name: setup-spark
description: 'Run fuzz test'
inputs:
  native-engine:
    description: 'type of spark native engine (eg. blaze/comet/gluten)'
    required: true
  native-engine-jar:
    description: 'native engine jar file'
    required: true
runs:
  using: composite
  steps:
#    - name: Download fuzz test lib
#      uses: actions/download-artifact@v4
#      with:
#        name: fuzz-test-spark-${{ github.run_id }}
    - name: Get cached fuzz test lib
      id: get-fuzz-test-cache
      uses: actions/cache/restore@v4
      with:
        path: fuzz-test-spark-native-*.jar
        key: fuzz-test-spark-native-lib-${{ hashFiles('pom.xml', '**/*.scala', '**/*.java') }}
        restore-keys:
          fuzz-test-spark-native-lib-
        enableCrossOsArchive: true
        fail-on-cache-miss: true
    - name: Copy native engine jar to spark jars
      shell: bash
      run: |
        cp ${{ inputs.native-engine-jar }} $SPARK_HOME/jars
    - name: Generate data
      shell: bash
      run: |
        FUZZ_TEST_JAR=$(ls fuzz-test-spark-native-*.jar)
        $SPARK_HOME/bin/spark-submit \
          --master local \
          --class cn.wangz.spark.fuzz.Main \
          $FUZZ_TEST_JAR \
          data --num-files=2 --num-rows=200 --num-columns=100
    - name: Generate queries
      shell: bash
      run: |
        FUZZ_TEST_JAR=$(ls fuzz-test-spark-native-*.jar)
        $SPARK_HOME/bin/spark-submit \
          --master local \
          --class cn.wangz.spark.fuzz.Main \
          $FUZZ_TEST_JAR \
          queries --num-files=2 --num-queries=500
    - name: Run queries
      shell: bash
      run: |
        FUZZ_TEST_JAR=$(ls fuzz-test-spark-native-*.jar)
        $SPARK_HOME/bin/spark-submit \
          --master local \
          --class cn.wangz.spark.fuzz.Main \
          $FUZZ_TEST_JAR \
          run --native-engine=${{ inputs.native-engine }} --num-files=2 --filename=queries.sql
